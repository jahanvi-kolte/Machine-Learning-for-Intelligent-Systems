{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<h2>Project 0: Julia Basics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<h3>Introduction</h3>\n",
    "\n",
    "<p>In this project, you will write a function to compute Euclidean distances between sets of vectors, and get familiar with the Vocareum system that we will be using this semester. </p>\n",
    "\n",
    "<strong>How to submit:</strong> You can submit your code using the red <strong>Submit</strong> button above. This button will send any code below surrounded by <strong>#&lt;GRADED&gt;</strong><strong>#&lt;/GRADED&gt;</strong> tags below to the autograder, which will then run several tests over your code. By clicking on the <strong>Details</strong> dropdown next to the Submit button, you will be able to view your submission report once the autograder has completed running. This submission report contains a summary of the tests you have failed or passed, as well as a log of any errors generated by your code when we ran it.\n",
    "\n",
    "Note that this may take a while depending on how long your code takes to run! Once your code is submitted you may navigate away from the page as you desire -- the most recent submission report will always be available from the Details menu.\n",
    "\n",
    "<p><strong>Evaluation:</strong> Your code will be autograded for technical\n",
    "correctness and--on some assignments--speed. Please <em>do not</em> change the names of any provided functions or classes within the code, or you will wreak havoc on the autograder. Furthermore, <em>any code not surrounded by <strong>#&lt;GRADED&gt;</strong><strong>#&lt;/GRADED&gt;</strong> tags will not be run by the autograder</em>. However, the correctness of your implementation -- not the autograder's output -- will be the final judge of your score.  If necessary, we will review and grade assignments individually to ensure that you receive due credit for your work.\n",
    "\n",
    "<p><strong>Academic Integrity:</strong> We will be checking your code against other submissions in the class for logical redundancy. If you copy someone else's code and submit it with minor changes, we will know. These cheat detectors are quite hard to fool, so please don't try. We trust you all to submit your own work only; <em>please</em> don't let us down. If you do, we will pursue the strongest consequences available to us.\n",
    "\n",
    "<p><strong>Getting Help:</strong> You are not alone!  If you find yourself stuck  on something, contact the course staff for help.  Office hours, section, and the <a href=\"https://piazza.com/class/icxgflcnpra3ko\">Piazza</a> are there for your support; please use them.  If you can't make our office hours, let us know and we will schedule more.  We want these projects to be rewarding and instructional, not frustrating and demoralizing.  But, we don't know when or how to help unless you ask.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "In this and future projects should you choose you use python, you will make a great deal of use of the numpy package. Numpy is a package that contains many routines for fast matrix and vector operations. Behind the scenes, rather than executing slow Python code, numpy functions often execute code that is compiled and highly optimized.\n",
    "\n",
    "If you are not familiar with the Numpy package, you can read an overview of it <a href=\"https://docs.scipy.org/doc/numpy-dev/user/quickstart.html\">here</a>, and find a full API <a href=\"https://docs.scipy.org/doc/numpy/reference/\">here</a>. We import numpy for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "import numpy as np # Numpy is Python's built in library for matrix operations.\n",
    "                   # We will be using it a lot in this class!\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "\n",
    "<h3> Euclidean distances in Python </h3>\n",
    "\n",
    "<p>Many machine learning algorithms access their input data primarily through pairwise distances. It is therefore important that we have a fast function that computes pairwise (Euclidean) distances of input vectors. Assume we have $n$ data vectors $\\vec x_1,\\dots,\\vec x_n\\in{\\cal R}^d$ and $m$ vectors $\\vec z_1,\\dots,z_m\\in{\\cal R}^d$. And let us define two matrices $X=[\\vec x_1,\\dots,\\vec x_n]\\in{\\cal R}^{d\\times n}$, where the $i^{th}$ column is a vector $\\vec x_i$ and similarly $Z=[\\vec z_1,\\dots,\\vec z_m]$. Our distance function takes as input the two matrices $X$ and $Z$ and outputs a matrix $D\\in{\\cal R}^{n\\times m}$, where \n",
    "\t$$D_{ij}=\\sqrt{(\\vec x_i-\\vec z_j)^\\top (\\vec x_i-\\vec z_j)}.$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "A naÃ¯ve implementation to compute pairwise distances may look like the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def l2distanceSlow(X,Z=None):\n",
    "    if Z is None:\n",
    "        Z = X\n",
    "    \n",
    "    n,d = X.shape     # dimension of X\n",
    "    m= Z.shape[0]     # dimension of Z\n",
    "    D=np.zeros((n,m)) # allocate memory for the output matrix\n",
    "    for i in range(n):     # loop over vectors in X\n",
    "        for j in range(m): # loop over vectors in Z\n",
    "            D[i,j]=0.0; \n",
    "            for k in range(d): # loop over dimensions\n",
    "                D[i,j]=D[i,j]+(X[i,k]-Z[j,k])**2; # compute l2-distance between the ith and jth vector\n",
    "            D[i,j]=np.sqrt(D[i,j]); # take square root\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Please read through the code carefully and make sure you understand it. It is perfectly correct and will produce the correct result ... eventually. To see what is wrong, try running the l2distanceSlow code on an extremely small matrix X:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the naive version for the first time ...\n",
      "CPU times: user 41 s, sys: 0 ns, total: 41 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "X=np.random.rand(700,100)\n",
    "print(\"Running the naive version for the first time ...\")\n",
    "%time D=l2distanceSlow(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 17.32050808  22.5166605 ]\n",
      " [ 12.12435565  17.32050808]\n",
      " [  6.92820323  12.12435565]]\n",
      "[[ 17.32050808  22.5166605 ]\n",
      " [ 12.12435565  17.32050808]\n",
      " [  6.92820323  12.12435565]]\n",
      "[[  0.           5.19615242  10.39230485]\n",
      " [  5.19615242   0.           5.19615242]\n",
      " [ 10.39230485   5.19615242   0.        ]]\n",
      "[[  0.           5.19615242  10.39230485]\n",
      " [  5.19615242   0.           5.19615242]\n",
      " [ 10.39230485   5.19615242   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A=np.matrix([[1,2,3],[4,5,6],[7,8,9]])\n",
    "B=np.matrix([[11,12,13],[14,15,16]])\n",
    "print(l2distanceSlow(A,B))\n",
    "print(l2distance(A,B))\n",
    "\n",
    "\n",
    "print(l2distanceSlow(A))\n",
    "print(l2distance(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]]\n",
      "[[ 10.  11.  12.]\n",
      " [ 13.  14.  15.]\n",
      " [  0.   0.   0.]]\n",
      "[[ 15.58845727  20.78460969]\n",
      " [ 10.39230485  15.58845727]\n",
      " [  5.19615242  10.39230485]]\n",
      "2\n",
      "\n",
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]]\n",
      "[[ 10.  11.  12.]\n",
      " [ 13.  14.  15.]\n",
      " [  0.   0.   0.]]\n",
      "[[ 243.  243. -216.]\n",
      " [ 243.  243. -216.]\n",
      " [-216. -216.  194.]]\n",
      "[[ 15.58845727  15.58845727  14.69693846]\n",
      " [ 15.58845727  15.58845727  14.69693846]\n",
      " [ 14.69693846  14.69693846  13.92838828]]\n",
      "[[ 243.  324.   50.]\n",
      " [ 162.  243.  122.]\n",
      " [-482. -554.  194.]]\n",
      "[[ 15.58845727  18.           7.07106781]\n",
      " [ 12.72792206  15.58845727  11.04536102]\n",
      " [ 21.9544984   23.53720459  13.92838828]]\n"
     ]
    }
   ],
   "source": [
    "P=np.matrix([[1,2,3],[4,5,6],[7,8,9]])\n",
    "Q=np.matrix([[10,11,12],[13,14,15]])\n",
    "maxNum=max(P.shape[0],Q.shape[0])\n",
    "\n",
    "Z3=np.zeros((maxNum,maxNum))\n",
    "# if P.shape[0]!=maxNum:\n",
    "    \n",
    "Z3[:P.shape[0],:P.shape[1]]=P\n",
    "print(Z3)\n",
    "    \n",
    "if Q.shape[0]!=maxNum:\n",
    "    Z2=np.zeros((maxNum,maxNum))\n",
    "    #print(Z1[:Q.shape[0],:Q.shape[1]])\n",
    "    #print(Z1)\n",
    "    Z2[:Q.shape[0],:Q.shape[1]]=Q   \n",
    "\n",
    "print(Z2)\n",
    "\n",
    "D1=l2distanceSlow(P,Q)\n",
    "print(D1)\n",
    "print(P.ndim)\n",
    "\n",
    "print()\n",
    "print(Z3)\n",
    "print(Z2)\n",
    "D2=innerproduct(Z3)+innerproduct(Z2)-innerproduct(Z3,Z2)-innerproduct(Z2,Z3)\n",
    "print(D2)\n",
    "print(np.sqrt(abs(D2)))\n",
    "\n",
    "\n",
    "D2=innerproduct(Z3)+innerproduct(Z2)-2*innerproduct(Z3,Z2)\n",
    "print(D2)\n",
    "print(np.sqrt(abs(D2)))\n",
    "\n",
    "#D2=l2distance(P,Q)\n",
    "#print(D2)\n",
    "\n",
    "# A=np.matrix([[1,2,3]])\n",
    "# B=np.matrix([[10,11,12]])\n",
    "# print(innerproduct(A,B))\n",
    "# print (innerproduct(B,A))\n",
    "# print (innerproduct(A))\n",
    "# print(innerproduct(Q.resize(3,3)))\n",
    "# print(P.dtype)\n",
    "#print(innerproduct(P).sum(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4  9]\n",
      " [16 25 36]]\n",
      "[14 77]\n",
      "[[14 14 14]\n",
      " [77 77 77]]\n",
      "[[11 14]\n",
      " [12 15]\n",
      " [13 16]]\n",
      "[[434 677]\n",
      " [434 677]\n",
      " [434 677]]\n"
     ]
    }
   ],
   "source": [
    "A=[[1,2,3],[4,5,6]]\n",
    "B=[[1,2,3],[4,5,6]]\n",
    "# print(np.einsum('ij,ij',A,B))\n",
    "# print(np.einsum('ij->i',A,B))\n",
    "\n",
    "\n",
    "\n",
    "print(np.einsum('ij,ij->ij',A,B))\n",
    "print(np.einsum('ij,ij->i',A,B))\n",
    "\n",
    "S=np.tile(np.einsum('ij,ij->i',A,B),3).reshape((3,2\n",
    "                     )).T\n",
    "print(S)\n",
    "\n",
    "P=np.matrix([[11,12,13],[14,15,16]])\n",
    "\n",
    "print(P.T)\n",
    "R=np.tile(np.einsum('ij,ij->j',P.T,P.T),3).reshape(3,2)\n",
    "# R=np.tile(np.einsum('ij,ij->j',P,P),3).reshape((3,2))\n",
    "print(R)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This code defines some random data in $X$ and computes the corresponding distance matrix $D$. The <em>%time</em> statements time how long this takes. When I ran the code, the <em>l2distanceSlow</em> function took <strong>43.6s to run</strong>! \n",
    "\n",
    "This is an appallingly large amount of time for such a simple operation on a small amount of data, and writing code like this to deal with matrices in this class will result in code that takes <strong>days</strong> to run. \n",
    "\n",
    "\n",
    "<strong>As a general rule, you should avoid tight loops at all cost.</strong> As we will see in the remainder of this assignment, we can do much better by performing bulk matrix operations using the <em>numpy</em> package, which calls highly optimized compiled code behind the scenes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<h4> How to program in Julia / Matlab / Numpy </h4>\n",
    "\n",
    "<p>Although there is an execution overhead per line in Python, matrix operations are extremely optimized and very fast. In order to successfully program in this course, you need to free yourself from \"for-loop\" thinking and start thinking in terms of matrix operations. Python for scientific computing can be very fast if almost all the time is spent in a few heavy duty matrix operations. In this assignment you will do this, and transform the function above into a few matrix operations <em>without any loops at all.</em> </p> \n",
    "\n",
    "<p>The key to efficient programming in Python for machine learning in general is to think about it in terms of mathematics, and not in terms of Loops. </p>\n",
    "\n",
    "<p>\t(a) Show that the Gram matrix (aka inner-product matrix)\n",
    "$$\tG_{ij}=\\vec x_i^\\top\\vec z_j $$\n",
    "can be expressed in terms of a pure matrix multiplication. Once you are done with the derivation, implement the function <strong><code>innerproduct</code></strong>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "Correctness",
     "locked": false,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def innerproduct(X,Z=None):\n",
    "    # function innerproduct(X,Z)\n",
    "    #\n",
    "    # Computes the inner-product matrix.\n",
    "    # Syntax:\n",
    "    # D=innerproduct(X,Z)\n",
    "    # Input:\n",
    "    # X: nxd data matrix with n vectors (rows) of dimensionality d\n",
    "    # Z: mxd data matrix with m vectors (rows) of dimensionality d\n",
    "    #\n",
    "    # Output:\n",
    "    # Matrix G of size nxm\n",
    "    # G[i,j] is the inner-product between vectors X[i,:] and Z[j,:]\n",
    "    #\n",
    "    # call with only one input:\n",
    "    # innerproduct(X)=innerproduct(X,X)\n",
    "    #\n",
    "    if Z is None: # case when there is only one input (X)\n",
    "        G=np.matmul(X,X.transpose())\n",
    "    else:  # case when there are two inputs (X,Z)\n",
    "        G=np.matmul(X,Z.transpose())\n",
    "    \n",
    "    return G\n",
    "#</GRADED>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If your code is correct you should pass the following two tests below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# a simple test for the innerproduct function\n",
    "M=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "Q=np.array([[11,12,13],[14,15,16]])\n",
    "print(np.linalg.norm(innerproduct(M,M)-innerproduct(M))<1e-16) # test1: Inner product with itself\n",
    "print(np.all(innerproduct(M,Q).T==np.array([[74,182,290],[92,227,362]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "(b) Let us define two new matrices $S,R\\in{\\cal R}^{n\\times m}$ \n",
    "\t\t$$S_{ij}=\\vec x_i^\\top\\vec x_i, \\ \\ R_{ij}=\\vec z_j^\\top\\vec z_j.$$\n",
    " \tShow that the <em>squared</em>-euclidean matrix $D^2\\in{\\cal R}^{n\\times m}$, defined as\n",
    "\t\t$$D^2_{ij}=(\\vec x_i-\\vec z_j)^2,$$\n",
    "\tcan be expressed as a linear combination of the matrix $S, G, R$. (Hint: It might help to first express $D^2_{ij}$ in terms of inner-products.) What do you need to do to obtain the true Euclidean distance matrix $D$?</p></td>\n",
    "\t\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<p>\t(c) Implement the function <strong><code>l2distance</code></strong>, which computes the Euclidean distance matrix $D$ without a single loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def l2distance(X,Z=None):\n",
    "    # function D=l2distance(X,Z)\n",
    "    #\n",
    "    # Computes the Euclidean distance matrix.\n",
    "    # Syntax:\n",
    "    # D=l2distance(X,Z)\n",
    "    # Input:\n",
    "    # X: nxd data matrix with n vectors (rows) of dimensionality d\n",
    "    # Z: mxd data matrix with m vectors (rows) of dimensionality d\n",
    "    #\n",
    "    # Output:\n",
    "    # Matrix D of size nxm\n",
    "    # D(i,j) is the Euclidean distance of X(i,:) and Z(j,:)\n",
    "    #\n",
    "    # call with only one input:\n",
    "    # l2distance(X)=l2distance(X,X)\n",
    "    #\n",
    "\n",
    "    if Z is None:\n",
    "#          D=innerproduct(X)+innerproduct(Z)-innerproduct(X,Z)-innerproduct(Z,X)\n",
    "        m=n=X.shape[0]\n",
    "        d=X.shape[1]\n",
    "#         m=X.shape[0]\n",
    "        \n",
    "        S=np.tile(np.einsum('ij,ij->i',X,X),m).reshape((m,n)).T\n",
    "        R=np.tile(np.einsum('ij,ij->j',X.T,X.T),n).reshape(n,m)\n",
    "        G=2*innerproduct(X,X)\n",
    "        D=S+R-G\n",
    "    else:  # case when there are two inputs (X,Z)\n",
    "#         D=innerproduct(X)+innerproduct(Z)-innerproduct(X,Z)-innerproduct(Z,X)\n",
    "        n=X.shape[0]\n",
    "        d=X.shape[1]\n",
    "        m=Z.shape[0]\n",
    "        \n",
    "        S=np.tile(np.einsum('ij,ij->i',X,X),m).reshape((m,n)).T\n",
    "        R=np.tile(np.einsum('ij,ij->j',Z.T,Z.T),n).reshape(n,m)\n",
    "        G=2*innerproduct(X,Z)\n",
    "        D=S+R-G\n",
    "                 \n",
    "        \n",
    "        \n",
    "    return np.sqrt(np.absolute(D))\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Test your l2-distance function again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the naive version ...\n",
      "Running the vectorized version ...\n",
      "The numpy code was 2477.6111111111113 times faster!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "current_time = lambda: int(round(time.time() * 1000))\n",
    "\n",
    "X=np.random.rand(700,100)\n",
    "Z=np.random.rand(300,100)\n",
    "\n",
    "print(\"Running the naive version ...\")\n",
    "before = current_time()\n",
    "D=l2distanceSlow(X)\n",
    "after = current_time()\n",
    "t_slow = after - before\n",
    "\n",
    "print(\"Running the vectorized version ...\")\n",
    "before = current_time()\n",
    "D=l2distance(X)\n",
    "after = current_time()\n",
    "t_fast = after - before\n",
    "\n",
    "speedup = t_slow / t_fast\n",
    "print(\"The numpy code was {} times faster!\".format(speedup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "How much faster is your code now? With this implementation you should easily be able to compute the distances between <strong>many more</strong> vectors. You can easily see how, even for small datasets, the for-loop based implementation could take several days or even weeks to perform basic operations that take seconds or minutes with well-written numpy code."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
